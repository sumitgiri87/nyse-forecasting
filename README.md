# NYSE — Next-Day / Next-Week Stock Prediction

**Project goal:** Build a simple, reproducible baseline that predicts (a) whether a stock's closing price will go up/down next day (classification) and (b) the next-week return (regression).

---

## 1. Problem statement

Given historical daily price data (open, high, low, close, volume) and optional company fundamentals, predict:

1. **Next-day direction (classification)** — will the closing price increase (1) or decrease (0) tomorrow?  
2. **Next-week return (regression)** — the percentage return over the next 5 trading days.

---

## 2. Repo layout

```text
ML-Team-Project/
├─ data/
│   ├─ raw/                      # raw CSV data files
│   └─ processed/                # processed data generated by src/data_processing.py
├─ experiments/                  # notebooks & results
├─ models/
├─ src/
│   ├─ utils/
│   │    └─ logger.py            # centralized logging
│   ├─ data_processing.py
│   ├─ features.py
│   ├─ train_and_eval.py
│   └─ experiment_tracking/      # contains docker-compose.yml, .env
├─ requirements.txt
├─ README.md
└─ .gitignore
```
---

## 3. Environment setup

```bash
# create & activate virtual environment
python -m venv .venv
source .venv/Scripts/activate  # Windows Git Bash

# install required packages
pip install -r requirements.txt
```

---

## 4. Running experiment tracking services

1. Go to the experiment tracking folder:

```bash
cd src/experiment_tracking
```

2. Ensure Docker is running locally.  

3. Update `.env` with your credentials (example):

```text
MINIO_ROOT_USER=minio
MINIO_ROOT_PASSWORD=minio123
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres123
```

4. Build Docker containers:

```bash
docker compose build
```

5. Start services in background:

```bash
docker compose up -d
```

**Services started:**

| Service   | Default Port | Description                         |
|-----------|-------------|-------------------------------------|
| PgAdmin  | 5051        | Database for experiments            |
| MinIO     | 9000 (API), 9001 (Console) | Object storage for ML artifacts |
| MLflow    | 5001        | Experiment tracking server          |

6. Verify services:

```bash
docker ps
docker logs -f nsye_minio  # check MinIO logs if needed for example
```

7. Access the UIs:

- **MLflow:** [http://localhost:5001](http://localhost:5001)  
- **MinIO Console:** [http://localhost:9001](http://localhost:9001)    
- **PgAdmin:** [http://localhost:5051](http://localhost:5051)
    - Login using the credentials from your `.env` file:  
---

## 5. Stopping services

```bash
docker compose down
```

---

## 6. Tracking experiments

1. Prepare your data (e.g., scripts like `src/data_processing.py`).  
2. Generate features (e.g., `src/features.py`).  
3. Train and evaluate models (e.g., `src/train_and_eval.py`).  
4. **Experiment tracking:** MLflow automatically logs metrics, parameters, and artifacts to the configured artifact store (MinIO in this setup).  

> Experiments can be run from scripts or notebooks. To log properly, ensure that:
> - Your `.venv` is activated.  
> - Docker services (MLflow, PostgreSQL, MinIO) are running.  
> - Your MLflow client points to the correct tracking URI (e.g., `http://localhost:5001`) and artifact root.  

**Tip:** You can define a specific experiment folder or name in your MLflow client (using `mlflow.set_experiment("Experiment_Name")`) to organize logs and results without touching the container directly.
